{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ca0d88c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab4f8d64",
   "metadata": {},
   "source": [
    "## It's a manual practice just to help clarifying the concept"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f1910bd",
   "metadata": {},
   "source": [
    "#### .readlines()  output:   ( read each line as a list)\n",
    "['This is a story about dogs\\n',\n",
    " 'our canine pets\\n',\n",
    " 'Dogs are furry animals\\n']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3471f9bd",
   "metadata": {},
   "source": [
    "#### .read()  output:   ( read entire text as a string)\n",
    "'This is a story about dogs\\nour canine pets\\nDogs are furry animals\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f3225b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('UNZIP_FOR_NOTEBOOKS_FINAL\\\\18-Naive-Bayes-and-NLP\\\\One.txt','r') as f:\n",
    "    words=f.read().lower().split()\n",
    "    uni_words_one=set(words) # turn into set to remove duplicate words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2d51e5a2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'canine', 'furry', 'about', 'a', 'is', 'this', 'story', 'our', 'are', 'pets', 'dogs', 'animals'}\n"
     ]
    }
   ],
   "source": [
    "print(uni_words_one)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "df54f6b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('UNZIP_FOR_NOTEBOOKS_FINAL\\\\18-Naive-Bayes-and-NLP\\\\Two.txt','r') as f:\n",
    "    words_two=f.read().lower().split()\n",
    "    uni_words_two=set(words_two)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "11f65553",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'waves', 'about', 'water', 'catching', 'popular', 'a', 'fun', 'is', 'this', 'story', 'surfing', 'sport'}\n"
     ]
    }
   ],
   "source": [
    "print(uni_words_two)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "26c643df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'waves', 'water', 'popular', 'a', 'fun', 'is', 'this', 'story', 'surfing', 'are', 'animals', 'canine', 'furry', 'about', 'catching', 'our', 'pets', 'dogs', 'sport'}\n"
     ]
    }
   ],
   "source": [
    "all_uni_words=set()\n",
    "all_uni_words.update(uni_words_one)\n",
    "all_uni_words.update(uni_words_two)\n",
    "print(all_uni_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7646a515",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'waves': 0, 'water': 1, 'popular': 2, 'a': 3, 'fun': 4, 'is': 5, 'this': 6, 'story': 7, 'surfing': 8, 'are': 9, 'animals': 10, 'canine': 11, 'furry': 12, 'about': 13, 'catching': 14, 'our': 15, 'pets': 16, 'dogs': 17, 'sport': 18}\n"
     ]
    }
   ],
   "source": [
    "full_voc=dict()\n",
    "i=0\n",
    "for w in all_uni_words:\n",
    "    full_voc[w]=i\n",
    "    i+=1\n",
    "print(full_voc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "76d178bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_freq=[0]*len(full_voc)\n",
    "two_freq=[0]*len(full_voc)\n",
    "all_words=['']*len(full_voc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9283360c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('UNZIP_FOR_NOTEBOOKS_FINAL\\\\18-Naive-Bayes-and-NLP\\\\One.txt','r') as f:\n",
    "    doc1=f.read().lower().split()\n",
    "for i in doc1:\n",
    "    ind=full_voc[i]\n",
    "    one_freq[ind]+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9ae027c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('UNZIP_FOR_NOTEBOOKS_FINAL\\\\18-Naive-Bayes-and-NLP\\\\Two.txt','r') as f:\n",
    "    doc2=f.read().lower().split()\n",
    "for i in doc2:\n",
    "    ind=full_voc[i]\n",
    "    two_freq[ind]+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8b9cddee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1, 1, 1, 1, 3, 1, 1, 2, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "two_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "febcf91a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['waves', 'water', 'popular', 'a', 'fun', 'is', 'this', 'story', 'surfing', 'are', 'animals', 'canine', 'furry', 'about', 'catching', 'our', 'pets', 'dogs', 'sport']\n"
     ]
    }
   ],
   "source": [
    "for word in full_voc:\n",
    "    ind=full_voc[word]\n",
    "    all_words[ind]=word\n",
    "print(all_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "92e7a50e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>waves</th>\n",
       "      <th>water</th>\n",
       "      <th>popular</th>\n",
       "      <th>a</th>\n",
       "      <th>fun</th>\n",
       "      <th>is</th>\n",
       "      <th>this</th>\n",
       "      <th>story</th>\n",
       "      <th>surfing</th>\n",
       "      <th>are</th>\n",
       "      <th>animals</th>\n",
       "      <th>canine</th>\n",
       "      <th>furry</th>\n",
       "      <th>about</th>\n",
       "      <th>catching</th>\n",
       "      <th>our</th>\n",
       "      <th>pets</th>\n",
       "      <th>dogs</th>\n",
       "      <th>sport</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   waves  water  popular  a  fun  is  this  story  surfing  are  animals  \\\n",
       "0      0      0        0  1    0   1     1      1        0    1        1   \n",
       "1      1      1        1  1    1   3     1      1        2    0        0   \n",
       "\n",
       "   canine  furry  about  catching  our  pets  dogs  sport  \n",
       "0       1      1      1         0    1     1     2      0  \n",
       "1       0      0      1         1    0     0     0      1  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag_of_words=pd.DataFrame(data=[one_freq,two_freq],columns=all_words)\n",
    "bag_of_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e499ece",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e723056b",
   "metadata": {},
   "source": [
    "### Using sklearn to extracting features from text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5860aa95",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = ['This is a line',\n",
    "        \"This is another line\",\n",
    "       \"Completely different line\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "4aa74005",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a0c0698f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'line': 2, 'completely': 0, 'different': 1}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv=CountVectorizer(stop_words='english') # it will treat three lines as different documents\n",
    "sparse_mat= cv.fit_transform(text)      # get the unique voc on fit and perfom fequency count on these documents\n",
    "cv.vocabulary_                          # return a sparse matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "1f78f658",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0, 0, 1],\n",
       "        [0, 0, 1],\n",
       "        [1, 1, 1]], dtype=int64)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sparse_mat.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c70ead7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d936fdbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf=TfidfTransformer(sparse_mat)  # let the bag of words(sparse_mat) convert into tfidf frequency count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "4af7f476",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<3x6 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 10 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# or simply use tfidfVectorizer to complete those tasks above\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tv=TfidfVectorizer()\n",
    "tv_result=tv.fit_transform(text)\n",
    "tv_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97fc9ef4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea113675",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a49c650",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b80b63e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "903160c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32876aa9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "515e3f36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1181719",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab03fa7e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
